{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e77e17",
   "metadata": {},
   "source": [
    "# Forecasting Models\n",
    "\n",
    "## Objectives\n",
    "- Establish strong forecasting baselines\n",
    "- Train a deep learning forecasting model (PyTorch)\n",
    "- Compare models using clear metrics\n",
    "\n",
    "This notebook builds on the preprocessing logic from Notebook 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abdeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e70af8",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "To keep the notebook self-contained, we repeat minimal preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3f0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('../data/raw/LD2011_2014.txt')\n",
    "df = pd.read_csv(DATA_PATH, sep=';', index_col=0, parse_dates=True, decimal=',')\n",
    "\n",
    "ts = df[df.columns[0]].rename('load')\n",
    "\n",
    "n = len(ts)\n",
    "train_ts = ts.iloc[:int(0.7*n)]\n",
    "val_ts = ts.iloc[int(0.7*n):int(0.85*n)]\n",
    "\n",
    "mean, std = train_ts.mean(), train_ts.std()\n",
    "scale = lambda s: (s - mean) / std\n",
    "\n",
    "train_ts = scale(train_ts)\n",
    "val_ts = scale(val_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b282fd",
   "metadata": {},
   "source": [
    "## Sliding Window Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d249003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(series, input_len, horizon):\n",
    "    X, y = [], []\n",
    "    values = series.values\n",
    "    for i in range(len(values) - input_len - horizon + 1):\n",
    "        X.append(values[i:i+input_len])\n",
    "        y.append(values[i+input_len:i+input_len+horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "INPUT_LEN = 24 * 7\n",
    "HORIZON = 24\n",
    "\n",
    "X_train, y_train = create_windows(train_ts, INPUT_LEN, HORIZON)\n",
    "X_val, y_val = create_windows(val_ts, INPUT_LEN, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe4251",
   "metadata": {},
   "source": [
    "## Baseline Model: Seasonal Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5669f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3546049412385093)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seasonal_naive_forecast(X, season=24):\n",
    "    return X[:, -season:]\n",
    "\n",
    "y_pred_naive = seasonal_naive_forecast(X_val)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "naive_mae = mae(y_val, y_pred_naive)\n",
    "naive_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15039f70",
   "metadata": {},
   "source": [
    "## Deep Learning Model (N-BEATS-style MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095e07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNBeats(nn.Module):\n",
    "    def __init__(self, input_len, horizon):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_len, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "            nn.Linear(256, horizon)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = SimpleNBeats(INPUT_LEN, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ed066",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6f4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9920/2035466745.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xb = torch.tensor(xb, dtype=torch.float32)\n",
      "/tmp/ipykernel_9920/2035466745.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yb = torch.tensor(yb, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2972\n",
      "Epoch 2, Train Loss: 0.2745\n",
      "Epoch 3, Train Loss: 0.2624\n",
      "Epoch 4, Train Loss: 0.2483\n",
      "Epoch 5, Train Loss: 0.2360\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    list(zip(X_train, y_train)), batch_size=64, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    list(zip(X_val, y_val)), batch_size=64\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = torch.tensor(xb, dtype=torch.float32)\n",
    "        yb = torch.tensor(yb, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fb7a2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85118ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9920/2239188498.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xb = torch.tensor(xb, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal Naive MAE: 0.3546049412385093\n",
      "Deep Learning MAE: 0.3006225295616382\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    for xb, _ in val_loader:\n",
    "        xb = torch.tensor(xb, dtype=torch.float32)\n",
    "        preds.append(model(xb).numpy())\n",
    "\n",
    "preds = np.vstack(preds)\n",
    "\n",
    "dl_mae = mae(y_val[:len(preds)], preds)\n",
    "\n",
    "print('Seasonal Naive MAE:', naive_mae)\n",
    "print('Deep Learning MAE:', dl_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ab5ac",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Seasonal Naive provides a strong baseline\n",
    "- A simple deep learning model already improves performance\n",
    "- This setup enables residual-based anomaly detection in the next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
